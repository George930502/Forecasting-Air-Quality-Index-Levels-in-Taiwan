{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b01889b-6415-4029-b015-99781f3d1129",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "file_path = \"2024_01_08_AQI_Weather_dataset.csv\"\n",
    "data = pd.read_csv(file_path, low_memory = False)\n",
    "sorted_data = data.sort_values(by = ['sitename', 'datacreationdate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "270ffb1f-78cb-4295-947b-a1f917a24f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 58550 entries, 0 to 58549\n",
      "Data columns (total 24 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   datacreationdate    58550 non-null  object \n",
      " 1   sitename            58550 non-null  object \n",
      " 2   aqi                 58550 non-null  float64\n",
      " 3   so2                 58550 non-null  float64\n",
      " 4   co                  58550 non-null  float64\n",
      " 5   o3                  58550 non-null  float64\n",
      " 6   o3_8hr              58550 non-null  float64\n",
      " 7   pm10                58550 non-null  float64\n",
      " 8   pm2.5               58550 non-null  float64\n",
      " 9   no2                 58550 non-null  float64\n",
      " 10  nox                 58550 non-null  float64\n",
      " 11  no                  58550 non-null  float64\n",
      " 12  co_8hr              58550 non-null  float64\n",
      " 13  pm2.5_avg           58550 non-null  float64\n",
      " 14  pm10_avg            58550 non-null  float64\n",
      " 15  so2_avg             58550 non-null  float64\n",
      " 16  測站氣壓(hPa)           58550 non-null  float64\n",
      " 17  氣溫(℃)               58550 non-null  float64\n",
      " 18  相對溼度(%)             58550 non-null  float64\n",
      " 19  風速(m/s)             58550 non-null  float64\n",
      " 20  風向(360degree)       58550 non-null  float64\n",
      " 21  最大瞬間風(m/s)          58550 non-null  float64\n",
      " 22  最大瞬間風風向(360degree)  58550 non-null  float64\n",
      " 23  降水量(mm)             58550 non-null  float64\n",
      "dtypes: float64(22), object(2)\n",
      "memory usage: 10.7+ MB\n"
     ]
    }
   ],
   "source": [
    "sorted_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69dbdb2c-f087-45ef-bc7e-d7ccb934fe8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['datacreationdate'] = pd.to_datetime(data['datacreationdate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9646cadc-43b6-41a7-94ad-b1779e7dba1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns={\n",
    "    '測站氣壓(hPa)': 'station_pressure_hpa',\n",
    "    '氣溫(℃)': 'temperature_c',\n",
    "    '相對溼度(%)': 'relative_humidity',\n",
    "    '風速(m/s)': 'wind_speed_m_s',\n",
    "    '風向(360degree)': 'wind_direction_deg',\n",
    "    '最大瞬間風(m/s)': 'max_instant_wind_m_s',\n",
    "    '最大瞬間風風向(360degree)': 'max_instant_wind_direction_deg',\n",
    "    '降水量(mm)': 'precipitation_mm'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8689e21-c30a-4aec-94cb-0268687f3a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          datacreationdate           aqi           so2            co  \\\n",
      "count                58550  58550.000000  58550.000000  58550.000000   \n",
      "mean   2024-05-02 00:00:00     51.876362      1.381404      0.395295   \n",
      "min    2024-01-01 01:00:00     -1.000000      0.000000      0.000000   \n",
      "25%    2024-03-02 00:00:00     31.000000      0.800000      0.190000   \n",
      "50%    2024-05-02 00:00:00     47.000000      1.200000      0.300000   \n",
      "75%    2024-07-02 00:00:00     67.000000      1.700000      0.470000   \n",
      "max    2024-08-31 23:00:00    169.000000     80.400000      3.230000   \n",
      "std                    NaN     26.882942      1.335122      0.316834   \n",
      "\n",
      "                 o3        o3_8hr          pm10         pm2.5           no2  \\\n",
      "count  58550.000000  58550.000000  58550.000000  58550.000000  58550.000000   \n",
      "mean      27.279481     27.334644     31.272741     15.875730     11.794844   \n",
      "min        0.000000      0.300000      0.000000      0.000000      0.000000   \n",
      "25%       14.100000     15.900000     17.000000      8.000000      4.700000   \n",
      "50%       24.900000     25.400000     26.000000     13.000000      8.600000   \n",
      "75%       37.500000     36.600000     42.000000     21.000000     15.500000   \n",
      "max      122.800000     93.400000    416.000000    122.000000     77.800000   \n",
      "std       16.865446     14.719772     20.344933     11.122924      9.879741   \n",
      "\n",
      "                nox  ...      pm10_avg       so2_avg  station_pressure_hpa  \\\n",
      "count  58550.000000  ...  58550.000000  58550.000000          58550.000000   \n",
      "mean      18.634874  ...     30.850179      0.872383           1008.470097   \n",
      "min        0.000000  ...      0.000000      0.000000            954.800000   \n",
      "25%        6.000000  ...     17.000000      0.000000           1004.500000   \n",
      "50%       10.200000  ...     25.000000      1.000000           1008.000000   \n",
      "75%       20.100000  ...     41.000000      1.000000           1013.900000   \n",
      "max      278.600000  ...    210.000000      5.000000           1029.600000   \n",
      "std       21.830841  ...     18.328471      0.661557              7.739380   \n",
      "\n",
      "       temperature_c  relative_humidity  wind_speed_m_s  wind_direction_deg  \\\n",
      "count   58550.000000       58550.000000    58550.000000        58550.000000   \n",
      "mean       24.690547          78.271322        1.954326          155.265110   \n",
      "min         5.700000          17.000000        0.000000            0.000000   \n",
      "25%        20.400000          70.000000        0.900000           42.375000   \n",
      "50%        25.900000          80.000000        1.600000          147.000000   \n",
      "75%        28.900000          88.000000        2.600000          253.000000   \n",
      "max        37.800000         100.000000       15.600000          360.000000   \n",
      "std         5.736716          12.870725        1.550750          116.702253   \n",
      "\n",
      "       max_instant_wind_m_s  max_instant_wind_direction_deg  precipitation_mm  \n",
      "count          58550.000000                    58550.000000      58550.000000  \n",
      "mean               5.100796                      159.909281          0.220002  \n",
      "min                0.000000                        0.000000          0.000000  \n",
      "25%                2.800000                       56.000000          0.000000  \n",
      "50%                4.400000                      155.000000          0.000000  \n",
      "75%                6.600000                      256.000000          0.000000  \n",
      "max               35.300000                      360.000000         86.000000  \n",
      "std                3.124646                      111.764688          2.019500  \n",
      "\n",
      "[8 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "summary = data.describe()\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66d4b463-0783-4e1e-86c4-7196faf73241",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_mapping = {\n",
    "    'Good': 0,\n",
    "    'Moderate': 1,\n",
    "    'Unhealthy for Sensitive Groups': 2,\n",
    "    'Unhealthy': 3,\n",
    "    'Very Unhealthy': 4,\n",
    "    'Hazardous': 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8864320-b1b5-4b03-aa3f-408e560bae25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義 AQI 分類函數\n",
    "def aqi_to_category(aqi):\n",
    "    if aqi <= 50:\n",
    "        return 0\n",
    "    elif aqi <= 100:\n",
    "        return 1\n",
    "    elif aqi <= 150:\n",
    "        return 2\n",
    "    elif aqi <= 200:\n",
    "        return 3\n",
    "    elif aqi <= 300:\n",
    "        return 4\n",
    "    else:\n",
    "        return 5\n",
    "\n",
    "# 應用到數據\n",
    "data['AQI_level'] = data['aqi'].apply(aqi_to_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82a3edb2-a0d0-4fed-8b01-c4601283b52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "# 模型列表\n",
    "models = {\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'XGBoost': xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42),\n",
    "    'LightGBM': lgb.LGBMClassifier(random_state=42),\n",
    "    'HistGradientBoosting': HistGradientBoostingClassifier(random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "02404b6e-0d32-4739-bff2-f76c5d86de13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 所有特徵列（根據提供數據結構）\n",
    "all_features = [\n",
    "    'station_pressure_hpa', 'temperature_c', 'relative_humidity', 'wind_speed_m_s',\n",
    "    'wind_direction_deg', 'max_instant_wind_m_s', 'max_instant_wind_direction_deg', \n",
    "    'precipitation_mm', 'pm2.5', 'pm10', 'so2', 'no2', 'nox', 'o3', 'co', 'o3_8hr',\n",
    "    'co_8hr', 'pm2.5_avg', 'pm10_avg', 'so2_avg', 'no'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f218bf85-cd56-4766-9baa-61ffd1374cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "import time\n",
    "\n",
    "def evaluate_models(X, y):\n",
    "    \"\"\"\n",
    "    自動化評估多個模型的性能，並選擇最佳模型。\n",
    "    Args:\n",
    "        X: 特徵數據。\n",
    "        y: 目標數據。\n",
    "    Returns:\n",
    "        best_model_name: 性能最佳的模型名稱。\n",
    "        best_model: 性能最佳的模型對象。\n",
    "        results: 所有模型的性能指標。\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    best_accuracy = 0\n",
    "    best_ac_model_name = None\n",
    "    best_ac_model = None\n",
    "    best_f1_score = 0\n",
    "    best_f1_model_name = None\n",
    "    best_f1_model = None\n",
    "    \n",
    "    # 分割數據集\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    \n",
    "    # 遍歷模型列表\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"Training {model_name}...\")\n",
    "        \n",
    "        # 計算模型執行時間\n",
    "        start_time = time.time()\n",
    "        model.fit(X_train, y_train)\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        \n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # 計算準確率\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        # 計算F1-score\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        \n",
    "        results[model_name] = {\n",
    "            'F1-score': f1,\n",
    "            'accuracy': accuracy,\n",
    "            'time': elapsed_time\n",
    "        }\n",
    "        \n",
    "        print(f\"{model_name} accuracy: {accuracy:.4f}\")\n",
    "        print(f\"{model_name} F1-score: {f1:.4f}\")\n",
    "        print(f\"{model_name} Training Time: {elapsed_time:.2f} seconds\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        \n",
    "        # 更新 f1-score 最佳模型\n",
    "        if f1 > best_f1_score:\n",
    "            best_f1_score = f1\n",
    "            best_f1_model_name = model_name\n",
    "            best_f1_model = model\n",
    "            \n",
    "        # 更新 f1-score 最佳模型\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_ac_model_name = model_name\n",
    "            best_ac_model = model\n",
    "            \n",
    "    print(f\"\\nBest Model (accuracy): {best_ac_model_name} with accuracy: {best_accuracy:.4f}\")\n",
    "    print(f\"\\nBest Model (F1-score): {best_f1_model_name} with F1-score: {best_f1_score:.4f}\")\n",
    "    \n",
    "    return best_ac_model_name, best_ac_model, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7444474f-ac73-4835-87b4-f1a12a97f4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 24hr -> 1hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "852802de-b374-4915-92f8-257ecf1637ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Decision Tree...\n",
      "Decision Tree accuracy: 0.9032\n",
      "Decision Tree F1-score: 0.9031\n",
      "Decision Tree Training Time: 33.06 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.94      0.93      6383\n",
      "         1.0       0.89      0.87      0.88      4567\n",
      "         2.0       0.78      0.81      0.80       681\n",
      "         3.0       0.59      0.59      0.59        29\n",
      "\n",
      "    accuracy                           0.90     11660\n",
      "   macro avg       0.80      0.80      0.80     11660\n",
      "weighted avg       0.90      0.90      0.90     11660\n",
      "\n",
      "Training Random Forest...\n",
      "Random Forest accuracy: 0.9352\n",
      "Random Forest F1-score: 0.9347\n",
      "Random Forest Training Time: 89.22 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.96      0.96      6383\n",
      "         1.0       0.92      0.92      0.92      4567\n",
      "         2.0       0.89      0.83      0.86       681\n",
      "         3.0       0.80      0.41      0.55        29\n",
      "\n",
      "    accuracy                           0.94     11660\n",
      "   macro avg       0.89      0.78      0.82     11660\n",
      "weighted avg       0.93      0.94      0.93     11660\n",
      "\n",
      "Training KNN...\n",
      "KNN accuracy: 0.7268\n",
      "KNN F1-score: 0.7003\n",
      "KNN Training Time: 0.10 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.93      0.82      6383\n",
      "         1.0       0.72      0.54      0.62      4567\n",
      "         2.0       0.68      0.10      0.18       681\n",
      "         3.0       0.00      0.00      0.00        29\n",
      "\n",
      "    accuracy                           0.73     11660\n",
      "   macro avg       0.53      0.39      0.40     11660\n",
      "weighted avg       0.72      0.73      0.70     11660\n",
      "\n",
      "Training XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JMU\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\JMU\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\JMU\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\JMU\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [17:08:33] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost accuracy: 0.9437\n",
      "XGBoost F1-score: 0.9436\n",
      "XGBoost Training Time: 62.68 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.97      0.96      6383\n",
      "         1.0       0.93      0.93      0.93      4567\n",
      "         2.0       0.90      0.87      0.88       681\n",
      "         3.0       0.87      0.69      0.77        29\n",
      "\n",
      "    accuracy                           0.94     11660\n",
      "   macro avg       0.91      0.86      0.89     11660\n",
      "weighted avg       0.94      0.94      0.94     11660\n",
      "\n",
      "Training LightGBM...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.090643 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 93442\n",
      "[LightGBM] [Info] Number of data points in the train set: 46640, number of used features: 504\n",
      "[LightGBM] [Info] Start training from score -0.602526\n",
      "[LightGBM] [Info] Start training from score -0.937253\n",
      "[LightGBM] [Info] Start training from score -2.841092\n",
      "[LightGBM] [Info] Start training from score -5.988040\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "LightGBM accuracy: 0.9214\n",
      "LightGBM F1-score: 0.9234\n",
      "LightGBM Training Time: 17.14 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.95      0.95      6383\n",
      "         1.0       0.92      0.90      0.91      4567\n",
      "         2.0       0.84      0.78      0.81       681\n",
      "         3.0       0.13      0.48      0.20        29\n",
      "\n",
      "    accuracy                           0.92     11660\n",
      "   macro avg       0.71      0.78      0.72     11660\n",
      "weighted avg       0.93      0.92      0.92     11660\n",
      "\n",
      "Training HistGradientBoosting...\n",
      "HistGradientBoosting accuracy: 0.9301\n",
      "HistGradientBoosting F1-score: 0.9312\n",
      "HistGradientBoosting Training Time: 9.93 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.96      0.96      6383\n",
      "         1.0       0.92      0.91      0.92      4567\n",
      "         2.0       0.87      0.79      0.83       681\n",
      "         3.0       0.18      0.52      0.27        29\n",
      "\n",
      "    accuracy                           0.93     11660\n",
      "   macro avg       0.73      0.80      0.74     11660\n",
      "weighted avg       0.93      0.93      0.93     11660\n",
      "\n",
      "\n",
      "Best Model (accuracy): XGBoost with accuracy: 0.9437\n",
      "\n",
      "Best Model (F1-score): XGBoost with F1-score: 0.9436\n"
     ]
    }
   ],
   "source": [
    "# 計算滯後特徵\n",
    "lag_features = []\n",
    "for lag in range(1, 25):  # 滯後 24 小時\n",
    "    for feature in all_features:\n",
    "        lag_features.append(data.groupby('sitename')[feature].shift(lag).rename(f'{feature}_lag_{lag}'))\n",
    "\n",
    "# 合併滯後特徵\n",
    "lag_features_df = pd.concat(lag_features, axis=1)\n",
    "data_with_lags = pd.concat([data.reset_index(drop=True), lag_features_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# 添加目標變數\n",
    "data_with_lags['AQI_level_next'] = data_with_lags.groupby('sitename')['AQI_level'].shift(-1)\n",
    "\n",
    "# 刪除 NaN\n",
    "lag_columns = [f'{feature}_lag_{lag}' for feature in all_features for lag in range(1, 25)]\n",
    "data_24hr = data_with_lags.dropna(subset=lag_columns + ['AQI_level_next'])\n",
    "X_24hr = data_24hr[lag_columns]\n",
    "y_24hr = data_24hr['AQI_level_next']\n",
    "\n",
    "# 自動化模型選擇並記錄時間與 F1 Score\n",
    "best_model_name_24hr, best_model_24hr, results_24hr = evaluate_models(X_24hr, y_24hr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "62fec1ae-b521-4116-b5cc-b5b7aaa1814e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Features for 24-hour case:\n",
      "             feature  importance\n",
      "408  pm2.5_avg_lag_1    0.222589\n",
      "264        no2_lag_1    0.032886\n",
      "314         o3_lag_3    0.016160\n",
      "192      pm2.5_lag_1    0.013383\n",
      "284       no2_lag_21    0.011166\n",
      "360     o3_8hr_lag_1    0.007876\n",
      "313         o3_lag_2    0.007760\n",
      "193      pm2.5_lag_2    0.006687\n",
      "286       no2_lag_23    0.006021\n",
      "400    co_8hr_lag_17    0.005894\n"
     ]
    }
   ],
   "source": [
    "importance_df_24hr = pd.DataFrame({\n",
    "    'feature': X_24hr.columns,\n",
    "    'importance': best_model_24hr.feature_importances_\n",
    "}).sort_values(by='importance', ascending=False)\n",
    "\n",
    "# 顯示 Top 10 特徵\n",
    "top_10_features_24hr = importance_df_24hr.head(10)\n",
    "print(\"Top 10 Features for 24-hour case:\")\n",
    "print(top_10_features_24hr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab5c6dc-e89a-4c8f-8678-3108b094d5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1hr -> 1hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "758a34a4-aa36-453f-83ea-224a50300473",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Decision Tree...\n",
      "Decision Tree accuracy: 0.9107\n",
      "Decision Tree F1-score: 0.9107\n",
      "Decision Tree Training Time: 0.93 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.93      0.94      6383\n",
      "         1.0       0.89      0.89      0.89      4602\n",
      "         2.0       0.83      0.83      0.83       691\n",
      "         3.0       0.64      0.60      0.62        30\n",
      "\n",
      "    accuracy                           0.91     11706\n",
      "   macro avg       0.82      0.81      0.82     11706\n",
      "weighted avg       0.91      0.91      0.91     11706\n",
      "\n",
      "Training Random Forest...\n",
      "Random Forest accuracy: 0.9380\n",
      "Random Forest F1-score: 0.9376\n",
      "Random Forest Training Time: 12.33 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.96      0.96      6383\n",
      "         1.0       0.93      0.92      0.92      4602\n",
      "         2.0       0.90      0.87      0.89       691\n",
      "         3.0       0.79      0.37      0.50        30\n",
      "\n",
      "    accuracy                           0.94     11706\n",
      "   macro avg       0.89      0.78      0.82     11706\n",
      "weighted avg       0.94      0.94      0.94     11706\n",
      "\n",
      "Training KNN...\n",
      "KNN accuracy: 0.8924\n",
      "KNN F1-score: 0.8910\n",
      "KNN Training Time: 0.02 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.94      0.92      6383\n",
      "         1.0       0.88      0.85      0.86      4602\n",
      "         2.0       0.86      0.71      0.78       691\n",
      "         3.0       0.75      0.30      0.43        30\n",
      "\n",
      "    accuracy                           0.89     11706\n",
      "   macro avg       0.85      0.70      0.75     11706\n",
      "weighted avg       0.89      0.89      0.89     11706\n",
      "\n",
      "Training XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JMU\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [17:17:07] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost accuracy: 0.9393\n",
      "XGBoost F1-score: 0.9392\n",
      "XGBoost Training Time: 1.45 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.96      0.96      6383\n",
      "         1.0       0.93      0.92      0.92      4602\n",
      "         2.0       0.89      0.88      0.89       691\n",
      "         3.0       0.71      0.57      0.63        30\n",
      "\n",
      "    accuracy                           0.94     11706\n",
      "   macro avg       0.87      0.83      0.85     11706\n",
      "weighted avg       0.94      0.94      0.94     11706\n",
      "\n",
      "Training LightGBM...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002408 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3899\n",
      "[LightGBM] [Info] Number of data points in the train set: 46824, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score -0.606424\n",
      "[LightGBM] [Info] Start training from score -0.933719\n",
      "[LightGBM] [Info] Start training from score -2.828994\n",
      "[LightGBM] [Info] Start training from score -5.975028\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "LightGBM accuracy: 0.9387\n",
      "LightGBM F1-score: 0.9385\n",
      "LightGBM Training Time: 1.84 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.96      0.96      6383\n",
      "         1.0       0.93      0.92      0.92      4602\n",
      "         2.0       0.90      0.89      0.89       691\n",
      "         3.0       0.86      0.60      0.71        30\n",
      "\n",
      "    accuracy                           0.94     11706\n",
      "   macro avg       0.91      0.84      0.87     11706\n",
      "weighted avg       0.94      0.94      0.94     11706\n",
      "\n",
      "Training HistGradientBoosting...\n",
      "HistGradientBoosting accuracy: 0.9319\n",
      "HistGradientBoosting F1-score: 0.9319\n",
      "HistGradientBoosting Training Time: 0.87 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.96      0.95      6383\n",
      "         1.0       0.92      0.91      0.92      4602\n",
      "         2.0       0.90      0.82      0.86       691\n",
      "         3.0       0.39      0.57      0.46        30\n",
      "\n",
      "    accuracy                           0.93     11706\n",
      "   macro avg       0.79      0.82      0.80     11706\n",
      "weighted avg       0.93      0.93      0.93     11706\n",
      "\n",
      "\n",
      "Best Model (accuracy): XGBoost with accuracy: 0.9393\n",
      "\n",
      "Best Model (F1-score): XGBoost with F1-score: 0.9392\n"
     ]
    }
   ],
   "source": [
    "# 計算滯後 1 小時的特徵\n",
    "lag_features = []\n",
    "for feature in all_features:\n",
    "    lag_features.append(data.groupby('sitename')[feature].shift(1).rename(f'{feature}_lag_1'))\n",
    "\n",
    "# 合併滯後特徵\n",
    "lag_features_df = pd.concat(lag_features, axis=1)\n",
    "data_with_lags = pd.concat([data.reset_index(drop=True), lag_features_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# 添加目標變數\n",
    "data_with_lags['AQI_level_next'] = data_with_lags.groupby('sitename')['AQI_level'].shift(-1)\n",
    "\n",
    "# 刪除 NaN\n",
    "lag_columns = [f'{feature}_lag_1' for feature in all_features]\n",
    "data_1hr = data_with_lags.dropna(subset=lag_columns + ['AQI_level_next'])\n",
    "\n",
    "# 訓練資料\n",
    "X_1hr = data_1hr[lag_columns]\n",
    "y_1hr = data_1hr['AQI_level_next']\n",
    "\n",
    "# 自動化模型選擇\n",
    "best_model_name_1hr, best_model_1hr, results_1hr = evaluate_models(X_1hr, y_1hr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bdf65fd2-94d0-430e-9e74-ed52526de23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Features for 1-hour case:\n",
      "                   feature  importance\n",
      "17         pm2.5_avg_lag_1    0.652708\n",
      "8              pm2.5_lag_1    0.063519\n",
      "11               no2_lag_1    0.060177\n",
      "15            o3_8hr_lag_1    0.030955\n",
      "13                o3_lag_1    0.020974\n",
      "9               pm10_lag_1    0.018687\n",
      "12               nox_lag_1    0.017313\n",
      "18          pm10_avg_lag_1    0.014218\n",
      "14                co_lag_1    0.011050\n",
      "7   precipitation_mm_lag_1    0.010824\n"
     ]
    }
   ],
   "source": [
    "importance_df_1hr = pd.DataFrame({\n",
    "    'feature': X_1hr.columns,\n",
    "    'importance': best_model_1hr.feature_importances_\n",
    "}).sort_values(by='importance', ascending=False)\n",
    "\n",
    "# 顯示 Top 10 特徵\n",
    "top_10_features_1hr = importance_df_1hr.head(10)\n",
    "print(\"Top 10 Features for 1-hour case:\")\n",
    "print(top_10_features_1hr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf782b7-5dee-41cb-8e94-0402a0b4a8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 24hr -> 24hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "65e55f22-13dd-4de5-8dd3-ecc770e04541",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JMU\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [17:51:45] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\JMU\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [17:52:26] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\JMU\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [17:53:06] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\JMU\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [17:53:47] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\JMU\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [17:54:31] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\JMU\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [17:55:20] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\JMU\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [17:56:08] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\JMU\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [17:56:59] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\JMU\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [17:57:50] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\JMU\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [17:58:41] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\JMU\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [17:59:32] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\JMU\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:00:19] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\JMU\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:01:08] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\JMU\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:01:55] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\JMU\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:02:41] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\JMU\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:03:27] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\JMU\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:04:22] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\JMU\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:05:13] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\JMU\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:06:09] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\JMU\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:07:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\JMU\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:07:54] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\JMU\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:08:47] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\JMU\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:09:40] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\JMU\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:10:28] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hour 1 F1 Score: 0.9975\n",
      "Hour 2 F1 Score: 0.9949\n",
      "Hour 3 F1 Score: 0.9909\n",
      "Hour 4 F1 Score: 0.9884\n",
      "Hour 5 F1 Score: 0.9859\n",
      "Hour 6 F1 Score: 0.9853\n",
      "Hour 7 F1 Score: 0.9814\n",
      "Hour 8 F1 Score: 0.9802\n",
      "Hour 9 F1 Score: 0.9784\n",
      "Hour 10 F1 Score: 0.9755\n",
      "Hour 11 F1 Score: 0.9737\n",
      "Hour 12 F1 Score: 0.9717\n",
      "Hour 13 F1 Score: 0.9713\n",
      "Hour 14 F1 Score: 0.9671\n",
      "Hour 15 F1 Score: 0.9677\n",
      "Hour 16 F1 Score: 0.9684\n",
      "Hour 17 F1 Score: 0.9664\n",
      "Hour 18 F1 Score: 0.9665\n",
      "Hour 19 F1 Score: 0.9644\n",
      "Hour 20 F1 Score: 0.9650\n",
      "Hour 21 F1 Score: 0.9657\n",
      "Hour 22 F1 Score: 0.9649\n",
      "Hour 23 F1 Score: 0.9641\n",
      "Hour 24 F1 Score: 0.9673\n",
      "\n",
      "Average F1 Score for 24 hours: 0.9751\n",
      "\n",
      "Hour 1 Accuracy: 0.9975\n",
      "Hour 2 Accuracy: 0.9949\n",
      "Hour 3 Accuracy: 0.9909\n",
      "Hour 4 Accuracy: 0.9884\n",
      "Hour 5 Accuracy: 0.9859\n",
      "Hour 6 Accuracy: 0.9853\n",
      "Hour 7 Accuracy: 0.9814\n",
      "Hour 8 Accuracy: 0.9802\n",
      "Hour 9 Accuracy: 0.9784\n",
      "Hour 10 Accuracy: 0.9755\n",
      "Hour 11 Accuracy: 0.9736\n",
      "Hour 12 Accuracy: 0.9717\n",
      "Hour 13 Accuracy: 0.9712\n",
      "Hour 14 Accuracy: 0.9671\n",
      "Hour 15 Accuracy: 0.9677\n",
      "Hour 16 Accuracy: 0.9683\n",
      "Hour 17 Accuracy: 0.9663\n",
      "Hour 18 Accuracy: 0.9664\n",
      "Hour 19 Accuracy: 0.9643\n",
      "Hour 20 Accuracy: 0.9650\n",
      "Hour 21 Accuracy: 0.9656\n",
      "Hour 22 Accuracy: 0.9649\n",
      "Hour 23 Accuracy: 0.9641\n",
      "Hour 24 Accuracy: 0.9673\n",
      "\n",
      "Average Accuracy for 24 hours: 0.9751\n"
     ]
    }
   ],
   "source": [
    "# 計算滯後 1~24 小時的特徵\n",
    "lag_features = []\n",
    "for lag in range(1, 25):  # 滯後 24 小時\n",
    "    for feature in all_features:\n",
    "        lag_features.append(data.groupby('sitename')[feature].shift(lag).rename(f'{feature}_lag_{lag}'))\n",
    "\n",
    "# 合併滯後特徵\n",
    "lag_features_df = pd.concat(lag_features, axis=1)\n",
    "data_with_lags = pd.concat([data.reset_index(drop=True), lag_features_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# 添加未來 24 小時的目標變數\n",
    "for lead in range(1, 25):\n",
    "    data_with_lags[f'AQI_level_future_{lead}'] = data_with_lags.groupby('sitename')['AQI_level'].shift(-lead)\n",
    "\n",
    "# 刪除 NaN\n",
    "future_cols = [f'AQI_level_future_{lead}' for lead in range(1, 25)]\n",
    "lag_columns = [f'{feature}_lag_{lag}' for feature in all_features for lag in range(1, 25)]\n",
    "data_future = data_with_lags.dropna(subset=lag_columns + future_cols)\n",
    "\n",
    "# 訓練資料\n",
    "X_future = data_future[lag_columns]\n",
    "y_future = data_future[future_cols]\n",
    "\n",
    "# 多輸出模型\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "multi_model = MultiOutputClassifier(xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42))\n",
    "multi_model.fit(X_future, y_future)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "# 預測與評估\n",
    "y_pred_future = multi_model.predict(X_future)\n",
    "\n",
    "# 計算每小時的 F1 Score\n",
    "f1_scores = []\n",
    "for i in range(24):\n",
    "    f1 = f1_score(y_future.iloc[:, i], y_pred_future[:, i], average='weighted')\n",
    "    f1_scores.append(f1)\n",
    "    print(f\"Hour {i+1} F1 Score: {f1:.4f}\")\n",
    "\n",
    "print(f\"\\nAverage F1 Score for 24 hours: {sum(f1_scores) / 24:.4f}\\n\")\n",
    "accuracys = []\n",
    "for i in range(24):\n",
    "    ac = accuracy_score(y_future.iloc[:, i], y_pred_future[:, i])\n",
    "    accuracys.append(ac)\n",
    "    print(f\"Hour {i+1} Accuracy: {ac:.4f}\")\n",
    "\n",
    "print(f\"\\nAverage Accuracy for 24 hours: {sum(accuracys) / 24:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bd817b79-9cd2-40e5-a0e1-60ec27bc689a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1173.9335584640503"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elapsed_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a409dbfa-3115-4d23-98fa-3c31f093eadc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'importance_df_24to24 = pd.DataFrame({\\n    \\'feature\\': X_future.columns,\\n    \\'importance\\': multi_model.feature_importances_\\n}).sort_values(by=\\'importance\\', ascending=False)\\n\\n# 顯示 Top 10 特徵\\ntop_10_features_24to24 = importance_df_24to24.head(10)\\nprint(\"Top 10 Features for 24to24-hour case:\")\\nprint(top_10_features_24to24)'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''importance_df_24to24 = pd.DataFrame({\n",
    "    'feature': X_future.columns,\n",
    "    'importance': multi_model.feature_importances_\n",
    "}).sort_values(by='importance', ascending=False)\n",
    "\n",
    "# 顯示 Top 10 特徵\n",
    "top_10_features_24to24 = importance_df_24to24.head(10)\n",
    "print(\"Top 10 Features for 24to24-hour case:\")\n",
    "print(top_10_features_24to24)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0738d447-63ec-4bb5-af41-a22af7ad1aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc686ea-6e42-4480-90b5-c67422b63ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1hr -> 1hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d7c9bea7-1a03-4382-8033-de7083a74416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>pm2.5_avg_lag_1</td>\n",
       "      <td>0.652708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pm2.5_lag_1</td>\n",
       "      <td>0.063519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>no2_lag_1</td>\n",
       "      <td>0.060177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>o3_8hr_lag_1</td>\n",
       "      <td>0.030955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>o3_lag_1</td>\n",
       "      <td>0.020974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pm10_lag_1</td>\n",
       "      <td>0.018687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>nox_lag_1</td>\n",
       "      <td>0.017313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>pm10_avg_lag_1</td>\n",
       "      <td>0.014218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>co_lag_1</td>\n",
       "      <td>0.011050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>precipitation_mm_lag_1</td>\n",
       "      <td>0.010824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   feature  importance\n",
       "17         pm2.5_avg_lag_1    0.652708\n",
       "8              pm2.5_lag_1    0.063519\n",
       "11               no2_lag_1    0.060177\n",
       "15            o3_8hr_lag_1    0.030955\n",
       "13                o3_lag_1    0.020974\n",
       "9               pm10_lag_1    0.018687\n",
       "12               nox_lag_1    0.017313\n",
       "18          pm10_avg_lag_1    0.014218\n",
       "14                co_lag_1    0.011050\n",
       "7   precipitation_mm_lag_1    0.010824"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_10_features_1hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e2365f6c-e868-4491-b7bc-b9d1535fcd92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Decision Tree...\n",
      "Decision Tree accuracy: 0.9082\n",
      "Decision Tree F1-score: 0.9081\n",
      "Decision Tree Training Time: 0.42 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.93      0.93      6383\n",
      "         1.0       0.88      0.89      0.89      4602\n",
      "         2.0       0.83      0.82      0.83       691\n",
      "         3.0       0.62      0.53      0.57        30\n",
      "\n",
      "    accuracy                           0.91     11706\n",
      "   macro avg       0.82      0.79      0.80     11706\n",
      "weighted avg       0.91      0.91      0.91     11706\n",
      "\n",
      "Training Random Forest...\n",
      "Random Forest accuracy: 0.9346\n",
      "Random Forest F1-score: 0.9343\n",
      "Random Forest Training Time: 9.46 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.96      0.95      6383\n",
      "         1.0       0.93      0.91      0.92      4602\n",
      "         2.0       0.89      0.87      0.88       691\n",
      "         3.0       0.82      0.47      0.60        30\n",
      "\n",
      "    accuracy                           0.93     11706\n",
      "   macro avg       0.90      0.80      0.84     11706\n",
      "weighted avg       0.93      0.93      0.93     11706\n",
      "\n",
      "Training KNN...\n",
      "KNN accuracy: 0.9241\n",
      "KNN F1-score: 0.9237\n",
      "KNN Training Time: 0.08 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.95      0.95      6383\n",
      "         1.0       0.91      0.90      0.91      4602\n",
      "         2.0       0.89      0.84      0.86       691\n",
      "         3.0       0.68      0.43      0.53        30\n",
      "\n",
      "    accuracy                           0.92     11706\n",
      "   macro avg       0.85      0.78      0.81     11706\n",
      "weighted avg       0.92      0.92      0.92     11706\n",
      "\n",
      "Training XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JMU\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:25:19] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost accuracy: 0.9372\n",
      "XGBoost F1-score: 0.9370\n",
      "XGBoost Training Time: 1.18 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.96      0.95      6383\n",
      "         1.0       0.93      0.91      0.92      4602\n",
      "         2.0       0.89      0.88      0.89       691\n",
      "         3.0       0.68      0.50      0.58        30\n",
      "\n",
      "    accuracy                           0.94     11706\n",
      "   macro avg       0.86      0.82      0.84     11706\n",
      "weighted avg       0.94      0.94      0.94     11706\n",
      "\n",
      "Training LightGBM...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001443 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1963\n",
      "[LightGBM] [Info] Number of data points in the train set: 46824, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -0.606424\n",
      "[LightGBM] [Info] Start training from score -0.933719\n",
      "[LightGBM] [Info] Start training from score -2.828994\n",
      "[LightGBM] [Info] Start training from score -5.975028\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "LightGBM accuracy: 0.9359\n",
      "LightGBM F1-score: 0.9356\n",
      "LightGBM Training Time: 1.59 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.96      0.95      6383\n",
      "         1.0       0.93      0.91      0.92      4602\n",
      "         2.0       0.88      0.89      0.88       691\n",
      "         3.0       0.87      0.43      0.58        30\n",
      "\n",
      "    accuracy                           0.94     11706\n",
      "   macro avg       0.91      0.80      0.83     11706\n",
      "weighted avg       0.94      0.94      0.94     11706\n",
      "\n",
      "Training HistGradientBoosting...\n",
      "HistGradientBoosting accuracy: 0.9318\n",
      "HistGradientBoosting F1-score: 0.9315\n",
      "HistGradientBoosting Training Time: 0.77 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.96      0.95      6383\n",
      "         1.0       0.92      0.91      0.92      4602\n",
      "         2.0       0.89      0.84      0.86       691\n",
      "         3.0       0.41      0.37      0.39        30\n",
      "\n",
      "    accuracy                           0.93     11706\n",
      "   macro avg       0.79      0.77      0.78     11706\n",
      "weighted avg       0.93      0.93      0.93     11706\n",
      "\n",
      "\n",
      "Best Model (accuracy): XGBoost with accuracy: 0.9372\n",
      "\n",
      "Best Model (F1-score): XGBoost with F1-score: 0.9370\n"
     ]
    }
   ],
   "source": [
    "X_1hr_top10 = X_1hr[importance_df_1hr.head(10)['feature'].tolist()]\n",
    "best_model_name_1hr_top_10, best_model_1hr_top_10, results_1hr_top_10 = evaluate_models(X_1hr_top10, y_1hr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a12b38d-6d74-4464-8248-760fc970ce93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 24hr -> 1hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6d83a424-70fa-4d51-87c4-04b777c7bab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>pm2.5_avg_lag_1</td>\n",
       "      <td>0.222589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>no2_lag_1</td>\n",
       "      <td>0.032886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>o3_lag_3</td>\n",
       "      <td>0.016160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>pm2.5_lag_1</td>\n",
       "      <td>0.013383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>no2_lag_21</td>\n",
       "      <td>0.011166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>o3_8hr_lag_1</td>\n",
       "      <td>0.007876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>o3_lag_2</td>\n",
       "      <td>0.007760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>pm2.5_lag_2</td>\n",
       "      <td>0.006687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>no2_lag_23</td>\n",
       "      <td>0.006021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>co_8hr_lag_17</td>\n",
       "      <td>0.005894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             feature  importance\n",
       "408  pm2.5_avg_lag_1    0.222589\n",
       "264        no2_lag_1    0.032886\n",
       "314         o3_lag_3    0.016160\n",
       "192      pm2.5_lag_1    0.013383\n",
       "284       no2_lag_21    0.011166\n",
       "360     o3_8hr_lag_1    0.007876\n",
       "313         o3_lag_2    0.007760\n",
       "193      pm2.5_lag_2    0.006687\n",
       "286       no2_lag_23    0.006021\n",
       "400    co_8hr_lag_17    0.005894"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_10_features_24hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e57e89af-fc8c-49bf-8a08-f2c5b4b66d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Decision Tree...\n",
      "Decision Tree accuracy: 0.8991\n",
      "Decision Tree F1-score: 0.8992\n",
      "Decision Tree Training Time: 0.41 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.93      0.93      6383\n",
      "         1.0       0.87      0.87      0.87      4567\n",
      "         2.0       0.79      0.77      0.78       681\n",
      "         3.0       0.51      0.72      0.60        29\n",
      "\n",
      "    accuracy                           0.90     11660\n",
      "   macro avg       0.78      0.83      0.80     11660\n",
      "weighted avg       0.90      0.90      0.90     11660\n",
      "\n",
      "Training Random Forest...\n",
      "Random Forest accuracy: 0.9326\n",
      "Random Forest F1-score: 0.9324\n",
      "Random Forest Training Time: 10.07 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.96      0.95      6383\n",
      "         1.0       0.92      0.91      0.92      4567\n",
      "         2.0       0.88      0.84      0.86       681\n",
      "         3.0       0.71      0.76      0.73        29\n",
      "\n",
      "    accuracy                           0.93     11660\n",
      "   macro avg       0.86      0.87      0.87     11660\n",
      "weighted avg       0.93      0.93      0.93     11660\n",
      "\n",
      "Training KNN...\n",
      "KNN accuracy: 0.9198\n",
      "KNN F1-score: 0.9195\n",
      "KNN Training Time: 0.10 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.95      0.94      6383\n",
      "         1.0       0.91      0.89      0.90      4567\n",
      "         2.0       0.86      0.81      0.83       681\n",
      "         3.0       0.69      0.76      0.72        29\n",
      "\n",
      "    accuracy                           0.92     11660\n",
      "   macro avg       0.85      0.85      0.85     11660\n",
      "weighted avg       0.92      0.92      0.92     11660\n",
      "\n",
      "Training XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JMU\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:28:23] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost accuracy: 0.9310\n",
      "XGBoost F1-score: 0.9308\n",
      "XGBoost Training Time: 1.33 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.96      0.95      6383\n",
      "         1.0       0.92      0.91      0.91      4567\n",
      "         2.0       0.86      0.82      0.84       681\n",
      "         3.0       0.64      0.86      0.74        29\n",
      "\n",
      "    accuracy                           0.93     11660\n",
      "   macro avg       0.84      0.89      0.86     11660\n",
      "weighted avg       0.93      0.93      0.93     11660\n",
      "\n",
      "Training LightGBM...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001292 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1964\n",
      "[LightGBM] [Info] Number of data points in the train set: 46640, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -0.602526\n",
      "[LightGBM] [Info] Start training from score -0.937253\n",
      "[LightGBM] [Info] Start training from score -2.841092\n",
      "[LightGBM] [Info] Start training from score -5.988040\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "LightGBM accuracy: 0.9271\n",
      "LightGBM F1-score: 0.9276\n",
      "LightGBM Training Time: 1.82 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.96      0.95      6383\n",
      "         1.0       0.92      0.90      0.91      4567\n",
      "         2.0       0.86      0.81      0.83       681\n",
      "         3.0       0.32      0.69      0.43        29\n",
      "\n",
      "    accuracy                           0.93     11660\n",
      "   macro avg       0.76      0.84      0.78     11660\n",
      "weighted avg       0.93      0.93      0.93     11660\n",
      "\n",
      "Training HistGradientBoosting...\n",
      "HistGradientBoosting accuracy: 0.9304\n",
      "HistGradientBoosting F1-score: 0.9304\n",
      "HistGradientBoosting Training Time: 0.74 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.96      0.95      6383\n",
      "         1.0       0.92      0.91      0.91      4567\n",
      "         2.0       0.85      0.82      0.84       681\n",
      "         3.0       0.39      0.48      0.43        29\n",
      "\n",
      "    accuracy                           0.93     11660\n",
      "   macro avg       0.78      0.79      0.78     11660\n",
      "weighted avg       0.93      0.93      0.93     11660\n",
      "\n",
      "\n",
      "Best Model (accuracy): Random Forest with accuracy: 0.9326\n",
      "\n",
      "Best Model (F1-score): Random Forest with F1-score: 0.9324\n"
     ]
    }
   ],
   "source": [
    "X_24hr_top10 = X_24hr[importance_df_24hr.head(10)['feature'].tolist()]\n",
    "best_model_name_24hr_top_10, best_model_24hr_top_10, results_24hr_top_10 = evaluate_models(X_24hr_top10, y_24hr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
